{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from sklearn.utils import shuffle\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess image function (distortion, color space conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crop the image to keep pixels 50-140 on the y axis while retaining the x axis and the 3(bgr) layers\n",
    "2. Resize the image to minimize the required memory and make the training faster, the target resize is the recommended amount from the Nvidia documentation\n",
    "3. Apply a small gaussian blur to reduce noise\n",
    "4. Convert the image to YUV color space to better the contrast for the learning process. As the Nvidia doc suggests, the YUV will allow the model to learn view the contrasting terrains/edges better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    #avoid input size error in keras model\n",
    "    new_img = img[50:140,:,:]\n",
    "    new_img = cv2.GaussianBlur(new_img, (3,3), 0)\n",
    "    new_img = cv2.resize(new_img,(200, 66), interpolation = cv2.INTER_AREA)\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV)\n",
    "    return new_img\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training data with pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Generator\n",
    "This generator is used to create extra training data by applying changes to the current images and adding them as new data.\n",
    "The first change is to make sure the images match our pre processing from the drive.py so we call pre_process() on each of them.\n",
    "Next we shuffle the data and if the angle size is greater or less than .33 we create a mirrored image and apply the opposite(to the original) angle and append that data to the data set. We then shuffle the data again before yielding the batch size back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def generate_training_data(image_paths, angles, batch_size=128):\n",
    "    image_paths, angles = shuffle(image_paths, angles)\n",
    "    X,y = ([],[])\n",
    "    while True:       \n",
    "        for i in range(len(angles)):\n",
    "            img = cv2.imread(image_paths[i])\n",
    "            angle = angles[i]\n",
    "            img = preprocess_image(img)\n",
    "            X.append(img)\n",
    "            y.append(angle)\n",
    "            if len(X) == batch_size:\n",
    "                yield (np.array(X), np.array(y))\n",
    "                X, y = ([],[])\n",
    "                image_paths, angles = shuffle(image_paths, angles)\n",
    "            # flip horizontally and invert steer angle, if magnitude is > 0.33 to avoid adding \n",
    "            # too much data without meaningful change\n",
    "            if abs(angle) > 0.33:\n",
    "                img = cv2.flip(img, 1)\n",
    "                angle *= -1\n",
    "                X.append(img)\n",
    "                y.append(angle)\n",
    "                if len(X) == batch_size:\n",
    "                    yield (np.array(X), np.array(y))\n",
    "                    X, y = ([],[])\n",
    "                    image_paths, angles = shuffle(image_paths, angles)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from the CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the CSV file driving_log.csv which contains data columns:\n",
    "- center image path, left image path, right image path, steering, throttle, brake, speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: (24108,) (24108,)\n"
     ]
    }
   ],
   "source": [
    "lines=[]\n",
    "image_paths = []\n",
    "angles = []\n",
    "img_path_prepend = ['', getcwd() + '/data/']\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    driving_data = list(csv.reader(csvfile, skipinitialspace=True, delimiter=',', quoting=csv.QUOTE_NONE))\n",
    "    for row in driving_data[1:]:\n",
    "        # skip it if ~0 speed - not representative of driving behavior\n",
    "        if float(row[6]) < 0.1 :\n",
    "            continue\n",
    "        # get center image path and angle\n",
    "        image_paths.append(img_path_prepend[1] + row[0])\n",
    "        angles.append(float(row[3]))\n",
    "        # get left image path and angle\n",
    "        image_paths.append(img_path_prepend[1] + row[1])\n",
    "        #add a correction factor of .25 to the angle\n",
    "        angles.append(float(row[3])+0.25)\n",
    "        # get left image path and angle\n",
    "        image_paths.append(img_path_prepend[1] + row[2])\n",
    "        # add a correction factor of -.25 to the angle\n",
    "        angles.append(float(row[3])-0.25)\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "angles = np.array(angles)\n",
    "print('Size of data:', image_paths.shape, angles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the data distribution and remove unwanted amount of driving without turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains a very large amount of data from a few steering angles most notably a 0 steering angle. This resulted in a model that is a lot more bias towards not turning or adjusting the the middle of the road. To fix this, we delete data from columns that have much more data values than the rest(more than 50% of the average to be exact) the average here being the amount of angles/23. Deleted data is selected at random after adding a keep_prob to every angle(1 if we dont want to remove any).\n",
    "\n",
    "The graph below shows the original angle data in the blue bars and the resulting data in orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c29d3c9550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data after removing unwanted values: (5634,) (5634,)\n"
     ]
    }
   ],
   "source": [
    "num_bins = 23\n",
    "avg_samples_per_bin = len(angles)/num_bins\n",
    "hist, bins = np.histogram(angles, num_bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.plot((np.min(angles), np.max(angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "#set keep probability for data from steering angles with more than half the average samples per angle\n",
    "keep_probs = []\n",
    "target = avg_samples_per_bin * .5\n",
    "for i in range(num_bins):\n",
    "    if hist[i] < target:\n",
    "        keep_probs.append(1.)\n",
    "    else:\n",
    "        keep_probs.append(1./(hist[i]/target))\n",
    "remove_list = []\n",
    "for i in range(len(angles)):\n",
    "    for j in range(num_bins):\n",
    "        if angles[i] > bins[j] and angles[i] <= bins[j+1]:\n",
    "            # delete from X and y with probability 1 - keep_probs[j]\n",
    "            if np.random.rand() > keep_probs[j]:\n",
    "                remove_list.append(i)\n",
    "image_paths = np.delete(image_paths, remove_list, axis=0)\n",
    "angles = np.delete(angles, remove_list)\n",
    "\n",
    "# print histogram to show the new distribution of steering angles\n",
    "hist, bins = np.histogram(angles, num_bins)\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.plot((np.min(angles), np.max(angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "plt.show()\n",
    "\n",
    "print('Size of data after removing unwanted values:', image_paths.shape, angles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model with Nvidia CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used below is the suggested Nvidia architecture.\n",
    "\n",
    "- Input size is 3@66x200\n",
    "- Convolutional Layer: 36 feature maps 5x5 Kernal - Output:36@14x47\n",
    "- Convolutional Layer: 48 feature maps 5x5 Kernal - Output:48@5x22\n",
    "- Convolutional Layer: 64 feature maps 3x3 Kernal - Output:64@3x20\n",
    "- Convolutional Layer: 64 feature maps 3x3 Kernal - Output:64@1x18\n",
    "- Flatten\n",
    "- Fully Connected Layer x4\n",
    "\n",
    "The generator is used to create more data for the training and validation sets. Since the data creation and shuffle provides enough changes we use the initial data set for both training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "154s - loss: 0.0331 - val_loss: 0.0242\n",
      "Epoch 2/5\n",
      "44s - loss: 0.0205 - val_loss: 0.0187\n",
      "Epoch 3/5\n",
      "93s - loss: 0.0158 - val_loss: 0.0129\n",
      "Epoch 4/5\n",
      "95s - loss: 0.0106 - val_loss: 0.0073\n",
      "Epoch 5/5\n",
      "53s - loss: 0.0067 - val_loss: 0.0050\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=(66,200,3)))\n",
    "##Nvidia Model\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "train_gen = generate_training_data(image_paths, angles, batch_size=64)\n",
    "val_gen = generate_training_data(image_paths, angles, batch_size=64)\n",
    "\n",
    "history = model.fit_generator(train_gen, validation_data=val_gen, nb_val_samples=2560, samples_per_epoch=23040, \n",
    "                                  nb_epoch=5, verbose=2, callbacks=[checkpoint])\n",
    "\n",
    "model.save('model.h5')\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
